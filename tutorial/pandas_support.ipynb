{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Introduction\n",
    "In this notebook, we will demonstrate the power and flexibility of the Evolutionary Forest Regressor, a machine learning algorithm that combines the strengths of decision trees and genetic programming, while supporting Pandas DataFrame as input. This makes it easy to work with complex data structures and perform data preprocessing efficiently. We will walk you through a simple example, primarily demonstrating how to generate a dataset, train the model, evaluate its performance, and most importantly, showcase the process of synthesizing high-order features using Pandas DataFrames as input."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Importing necessary libraries\n",
    "\n",
    "First, we import all the required libraries, including Pandas, NumPy, and the EvolutionaryForestRegressor from the evolutionary_forest package."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from evolutionary_forest.forest import EvolutionaryForestRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T10:11:09.074520Z",
     "end_time": "2023-04-17T10:11:09.239361Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: Generating a dataset\n",
    "\n",
    "We generate a synthetic dataset using the make_friedman1 function from the scikit-learn library, which creates a dataset with 100 samples, five features, and a single target variable. We then convert the NumPy arrays to Pandas DataFrames for better interpretability."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate dataset\n",
    "X, y = make_friedman1(n_samples=100, n_features=5, random_state=0)\n",
    "\n",
    "# Convert numpy arrays to pandas dataframe\n",
    "X = pd.DataFrame(X, columns=list(string.ascii_uppercase[:X.shape[1]]))\n",
    "y = pd.DataFrame(y, columns=['Target'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T10:11:09.091519Z",
     "end_time": "2023-04-17T10:11:09.294363Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Splitting the dataset\n",
    "\n",
    "To evaluate the performance of our model, we split the dataset into training and testing sets using the train_test_split function from scikit-learn, with 80% of the data reserved for training and the remaining 20% for testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T10:11:09.153060Z",
     "end_time": "2023-04-17T10:11:09.295360Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Training the Evolutionary Forest\n",
    "\n",
    "We instantiate an EvolutionaryForestRegressor with various hyperparameters, such as the maximum tree height, normalization, selection method, and base learner, among others. Next, we fit the model to the training data using the fit method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Train Evolutionary Forest\n",
    "r = EvolutionaryForestRegressor(max_height=5, normalize=True, select='AutomaticLexicase',\n",
    "                                gene_num=10, boost_size=100, n_gen=20, n_pop=200, cross_pb=1,\n",
    "                                base_learner='Random-DT', verbose=True, n_process=1)\n",
    "r.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T10:11:09.166066Z",
     "end_time": "2023-04-17T10:11:58.639655Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 5: Evaluating the model\n",
    "\n",
    "To evaluate the performance of our trained model, we use the r2_score metric from scikit-learn, which measures the proportion of variance in the target variable that is predictable from the input features. The closer the RÂ² score is to 1, the better the model is at predicting the target variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(r2_score(y_test, r.predict(x_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T10:11:58.642663Z",
     "end_time": "2023-04-17T10:11:59.378148Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 6: Analyzing feature importance\n",
    "\n",
    "Using the get_feature_importance and plot_feature_importance functions from the evolutionary_forest.utils module, we can visualize the importance of each feature in the dataset. This can provide valuable insights into which features contribute the most to the model's predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from evolutionary_forest.utils import get_feature_importance, plot_feature_importance\n",
    "\n",
    "code_importance_dict = get_feature_importance(r)\n",
    "plot_feature_importance(code_importance_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T10:11:58.896945Z",
     "end_time": "2023-04-17T10:11:59.834759Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 7: Synthesizing new features\n",
    "\n",
    "In this section, we highlight the ability of the Evolutionary Forest to synthesize new features while maintaining the output format as a Pandas DataFrame. This is particularly useful for keeping track of the newly created high-order features and their relationships with the original features.\n",
    "\n",
    "When using the feature_append function, it generates new features based on the top features identified earlier and appends them to the original DataFrame. The output is a Pandas DataFrame with column names that represent the high-order features, clearly indicating their relationship with the initial features. This makes it easy to interpret and understand the newly generated features and their potential impact on the model's performance.\n",
    "\n",
    "By maintaining the output as a Pandas DataFrame and providing meaningful column names, the Evolutionary Forest algorithm ensures a seamless integration with your existing data processing pipeline and allows you to further analyze and manipulate the synthesized features using the familiar and powerful Pandas library."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from evolutionary_forest.utils import feature_append\n",
    "\n",
    "# Synthesize new features\n",
    "code_importance_dict = get_feature_importance(r, simple_version=False)\n",
    "top_features = list(code_importance_dict.keys())[:len(code_importance_dict) // 2]\n",
    "new_train = feature_append(r, pd.DataFrame(r.x_scaler.transform(x_train), columns=x_train.columns), top_features,\n",
    "                           only_new_features=False)\n",
    "new_test = feature_append(r, pd.DataFrame(r.x_scaler.transform(x_train), columns=x_train.columns), top_features,\n",
    "                          only_new_features=False)\n",
    "new_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T10:11:59.837752Z",
     "end_time": "2023-04-17T10:11:59.893862Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "In this notebook, we demonstrated how the Evolutionary Forest Regressor can be used with Pandas DataFrames, making it a powerful tool for working with complex data structures. By showcasing its ability to generate insights, such as feature importance, and synthesize new features, we hope to inspire you to try out this versatile algorithm in your own data science projects.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
